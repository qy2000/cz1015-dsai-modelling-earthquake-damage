{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "EARTHQUAKE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZi6wTeYcnoX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f3e1c311-5bf2-4c5d-a42f-8d06716a16df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyZsoKNac42u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b70404c-f75d-4066-fea0-62b3924af708"
      },
      "source": [
        "%cd /content/drive/My Drive/'DSAI Project'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DSAI Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BknBvlTc-lD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "044e44d3-3018-40a8-e340-d222540a3e0c"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " catboost_info\t\t\t\t features.gdoc\n",
            "'Copy of DSAI Project (Draft 3).ipynb'\t'Mini Project.ipynb'\n",
            " data\t\t\t\t\t submission.csv\n",
            "'DSAI Project (Draft 3).ipynb'\t\t train_df_final.csv\n",
            " EARTHQUAKE.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caDfu9PhLEFZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9e14e39c-256b-40d3-f72b-cda871c08d37"
      },
      "source": [
        "# Basic Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt \n",
        "sb.set() \n",
        "\n",
        "from scipy import stats\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Visualization \n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.max_open_warning': 0}) # remove runtime warning for more than 20 figures\n",
        "import missingno as msn\n",
        "#import seaborn as sns already imported as sb\n",
        "plt.style.use('seaborn-whitegrid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2SBHPQMLEFc"
      },
      "source": [
        "train_values = pd.read_csv('data/train_values.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zau2x_DiLEFe"
      },
      "source": [
        "train_labels = pd.read_csv('data/train_labels.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVOKweRkLEFh"
      },
      "source": [
        "test_values = pd.read_csv('data/test_values.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCg7nhuBLEFj"
      },
      "source": [
        "train_data = pd.merge(train_values,train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nJXJCDiqSaV"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KdCMhlSIo3S"
      },
      "source": [
        "We first want to explore the damage grade data to see the distribution of damage grades through counting the values for each damage grade and running a cat plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxl2NCQILEFl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "983e9dbf-5be6-4a90-b8a3-37c9fd321918"
      },
      "source": [
        "#Damage grade in the Dataset\n",
        "print(\"Number of damage grades:\", len(train_data['damage_grade'].unique()))\n",
        "print(train_data['damage_grade'].value_counts())\n",
        "\n",
        "#Damage grade catplot\n",
        "sb.catplot(x = 'damage_grade', data = train_data, kind = 'count', height = 8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of damage grades: 3\n",
            "2    148259\n",
            "3     87218\n",
            "1     25124\n",
            "Name: damage_grade, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f0148848cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysd_Cac3JE7P"
      },
      "source": [
        "We also want to explore the data types of the variables to explore the different types of variables we have and if they coincide with the descriptions given in the problem description. As seen below, binary variables like the superstructure material columns and secondary use of building columns are of the integer data type, numerical variables like age, area percentage,height percentage, damage grade, building IDs and geo level IDs are of integer data type while categorical variables like land surface condition, foundation type, roof type, ground floor type, other floor type, position, plan configuration and legal ownership status are of object data type. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA20QOkQO9ru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "c0dfbc27-a726-4f42-bbd2-c3ff2d47b5f9"
      },
      "source": [
        "train_data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "building_id                                int64\n",
              "geo_level_1_id                             int64\n",
              "geo_level_2_id                             int64\n",
              "geo_level_3_id                             int64\n",
              "count_floors_pre_eq                        int64\n",
              "age                                        int64\n",
              "area_percentage                            int64\n",
              "height_percentage                          int64\n",
              "land_surface_condition                    object\n",
              "foundation_type                           object\n",
              "roof_type                                 object\n",
              "ground_floor_type                         object\n",
              "other_floor_type                          object\n",
              "position                                  object\n",
              "plan_configuration                        object\n",
              "has_superstructure_adobe_mud               int64\n",
              "has_superstructure_mud_mortar_stone        int64\n",
              "has_superstructure_stone_flag              int64\n",
              "has_superstructure_cement_mortar_stone     int64\n",
              "has_superstructure_mud_mortar_brick        int64\n",
              "has_superstructure_cement_mortar_brick     int64\n",
              "has_superstructure_timber                  int64\n",
              "has_superstructure_bamboo                  int64\n",
              "has_superstructure_rc_non_engineered       int64\n",
              "has_superstructure_rc_engineered           int64\n",
              "has_superstructure_other                   int64\n",
              "legal_ownership_status                    object\n",
              "count_families                             int64\n",
              "has_secondary_use                          int64\n",
              "has_secondary_use_agriculture              int64\n",
              "has_secondary_use_hotel                    int64\n",
              "has_secondary_use_rental                   int64\n",
              "has_secondary_use_institution              int64\n",
              "has_secondary_use_school                   int64\n",
              "has_secondary_use_industry                 int64\n",
              "has_secondary_use_health_post              int64\n",
              "has_secondary_use_gov_office               int64\n",
              "has_secondary_use_use_police               int64\n",
              "has_secondary_use_other                    int64\n",
              "damage_grade                               int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2PdwnuWL57w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3d93c1e8-d96e-41ef-8b89-9d3567fc4bd3"
      },
      "source": [
        "train_data.head(n=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>building_id</th>\n",
              "      <th>geo_level_1_id</th>\n",
              "      <th>geo_level_2_id</th>\n",
              "      <th>geo_level_3_id</th>\n",
              "      <th>count_floors_pre_eq</th>\n",
              "      <th>age</th>\n",
              "      <th>area_percentage</th>\n",
              "      <th>height_percentage</th>\n",
              "      <th>land_surface_condition</th>\n",
              "      <th>foundation_type</th>\n",
              "      <th>roof_type</th>\n",
              "      <th>ground_floor_type</th>\n",
              "      <th>other_floor_type</th>\n",
              "      <th>position</th>\n",
              "      <th>plan_configuration</th>\n",
              "      <th>has_superstructure_adobe_mud</th>\n",
              "      <th>has_superstructure_mud_mortar_stone</th>\n",
              "      <th>has_superstructure_stone_flag</th>\n",
              "      <th>has_superstructure_cement_mortar_stone</th>\n",
              "      <th>has_superstructure_mud_mortar_brick</th>\n",
              "      <th>has_superstructure_cement_mortar_brick</th>\n",
              "      <th>has_superstructure_timber</th>\n",
              "      <th>has_superstructure_bamboo</th>\n",
              "      <th>has_superstructure_rc_non_engineered</th>\n",
              "      <th>has_superstructure_rc_engineered</th>\n",
              "      <th>has_superstructure_other</th>\n",
              "      <th>legal_ownership_status</th>\n",
              "      <th>count_families</th>\n",
              "      <th>has_secondary_use</th>\n",
              "      <th>has_secondary_use_agriculture</th>\n",
              "      <th>has_secondary_use_hotel</th>\n",
              "      <th>has_secondary_use_rental</th>\n",
              "      <th>has_secondary_use_institution</th>\n",
              "      <th>has_secondary_use_school</th>\n",
              "      <th>has_secondary_use_industry</th>\n",
              "      <th>has_secondary_use_health_post</th>\n",
              "      <th>has_secondary_use_gov_office</th>\n",
              "      <th>has_secondary_use_use_police</th>\n",
              "      <th>has_secondary_use_other</th>\n",
              "      <th>damage_grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>802906</td>\n",
              "      <td>6</td>\n",
              "      <td>487</td>\n",
              "      <td>12198</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>r</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>q</td>\n",
              "      <td>t</td>\n",
              "      <td>d</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>v</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28830</td>\n",
              "      <td>8</td>\n",
              "      <td>900</td>\n",
              "      <td>2812</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>o</td>\n",
              "      <td>r</td>\n",
              "      <td>n</td>\n",
              "      <td>x</td>\n",
              "      <td>q</td>\n",
              "      <td>s</td>\n",
              "      <td>d</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>v</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94947</td>\n",
              "      <td>21</td>\n",
              "      <td>363</td>\n",
              "      <td>8973</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>r</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>x</td>\n",
              "      <td>t</td>\n",
              "      <td>d</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>v</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>590882</td>\n",
              "      <td>22</td>\n",
              "      <td>418</td>\n",
              "      <td>10694</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>r</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>d</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>v</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>201944</td>\n",
              "      <td>11</td>\n",
              "      <td>131</td>\n",
              "      <td>1488</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>t</td>\n",
              "      <td>r</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>d</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>v</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   building_id  geo_level_1_id  ...  has_secondary_use_other  damage_grade\n",
              "0       802906               6  ...                        0             3\n",
              "1        28830               8  ...                        0             2\n",
              "2        94947              21  ...                        0             3\n",
              "3       590882              22  ...                        0             2\n",
              "4       201944              11  ...                        0             3\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRujzUHdL1tm"
      },
      "source": [
        "Upon looking at the train data, we realise that the distribution of values of the building ID and geo level ID variables were too wide to do meaningful analysis with using graphical plots, hence have decided to leave them out of further analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6p1cEPtLEFo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "508f7685-b90a-4b9a-f0a3-60d899efb3cd"
      },
      "source": [
        "train_num = train_data[{'age','area_percentage','height_percentage','damage_grade'}]\n",
        "train_num.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>area_percentage</th>\n",
              "      <th>damage_grade</th>\n",
              "      <th>height_percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  area_percentage  damage_grade  height_percentage\n",
              "0   30                6             3                  5\n",
              "1   10                8             2                  7\n",
              "2   10                5             3                  5\n",
              "3   10                6             2                  5\n",
              "4   30                8             3                  9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejCLFvF3Zefk"
      },
      "source": [
        "We first explore the data by looking at the statistical description. As seen below, there are some variables, particularly the age of the buildings, that have particularly wide standard deviations, suggesting that there may be a wide range of values or some outliers. We will first do uni-variate analysis by plotting boxplots, kde and violin plot to further explore the data  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFgbwdZiO4Pq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "ce57a807-77ce-4a51-8928-d545cfe3a51d"
      },
      "source": [
        "train_num.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>area_percentage</th>\n",
              "      <th>damage_grade</th>\n",
              "      <th>height_percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>260601.000000</td>\n",
              "      <td>260601.000000</td>\n",
              "      <td>260601.000000</td>\n",
              "      <td>260601.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>26.535029</td>\n",
              "      <td>8.018051</td>\n",
              "      <td>2.238272</td>\n",
              "      <td>5.434365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>73.565937</td>\n",
              "      <td>4.392231</td>\n",
              "      <td>0.611814</td>\n",
              "      <td>1.918418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>15.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>995.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 age  area_percentage   damage_grade  height_percentage\n",
              "count  260601.000000    260601.000000  260601.000000      260601.000000\n",
              "mean       26.535029         8.018051       2.238272           5.434365\n",
              "std        73.565937         4.392231       0.611814           1.918418\n",
              "min         0.000000         1.000000       1.000000           2.000000\n",
              "25%        10.000000         5.000000       2.000000           4.000000\n",
              "50%        15.000000         7.000000       2.000000           5.000000\n",
              "75%        30.000000         9.000000       3.000000           6.000000\n",
              "max       995.000000       100.000000       3.000000          32.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqzrfaKqLEFq"
      },
      "source": [
        "# For loop for boxplot, kde, violinplot for each numerical variable\n",
        "# Uni-variate analysis\n",
        "for i in train_num.columns:\n",
        "    if i != 'damage_grade':\n",
        "        f, axes = plt.subplots(1,3,figsize= (16,8))\n",
        "        sb.boxplot(x= i, data= train_num, orient = \"h\", ax = axes[0])\n",
        "        sb.distplot(train_num[i], kde = True, ax = axes[1])\n",
        "        sb.violinplot(train_num[i], ax = axes[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q97LjoiZPhif"
      },
      "source": [
        "1.   Age:\n",
        "Skewed towards the left, with majority less than 200 but with plenty of outliers (extreme outlier around 1000)\n",
        "2.   Height_percentage:\n",
        "Skewed towards the left, with majority around 5 but with plenty of outliers\n",
        "3.   Count floors:\n",
        "Majority are just 2's, with some in 1 or 3 and minority outliers beyond these three\n",
        "4.   Area percentage:\n",
        "Skewed towards the left, with majority around 0 to 20 but with plenty of outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thy46Z1zaTqK"
      },
      "source": [
        "We then do a bi-variate analysis against damage grade to view the variables in relation to it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gT0Br83LEFv"
      },
      "source": [
        "# Bi-variate analysis\n",
        "# Joint boxplot for numerical against categorical data (damage_grade, the response variable)\n",
        "for i in train_num.columns:\n",
        "    if i != 'damage_grade':\n",
        "        f,axes = plt.subplots(1,1, figsize=(16,8))\n",
        "        sb.boxplot(x = i, y = \"damage_grade\", data = train_num, orient = \"h\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V9n2V45LEFz"
      },
      "source": [
        "1.   Age:\n",
        "Skewed towards the left, slight relation between damage_grade and age since the figures are quite similar. Thus, not a good predictor.\n",
        "All of them have an outlier around 1000\n",
        "2.   Height_percentage:\n",
        "Skewed towards the left, with majority around 5 but with plenty of outliers. Need to remove outliers for a more balanced data.\n",
        "3.   Count floors:\n",
        "Those with less than 2 are more likely to be in damage_grade 1, those greater than 2 are more likely to be in damage_grade 3.\n",
        "4.   Area percentage:\n",
        "Skewed towards the left, plenty of outliers. A slight relationship(?) since the figures are quite similar. Need to remove outliers for a more balanced data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdGvMVZQa1vP"
      },
      "source": [
        "Since most of the variables have much outliers, we explore how many outliers there are and filter out those that are not within 3 standard deviations from the mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg2uMIfod6Xt"
      },
      "source": [
        "# Finding number of outliers per column variable\n",
        "for col in train_num.columns:\n",
        "    if col != 'damage_grade':\n",
        "        # Calculate the Quartiles and IQR for each numerical variable\n",
        "        q1 = train_num[col].quantile(0.25)\n",
        "        q3 = train_num[col].quantile(0.75)\n",
        "        IQR = q3 - q1\n",
        "        outliers = 0\n",
        "        # Finding outlier for each numerical variable using for loop, then print\n",
        "        for data in train_num[col]:\n",
        "            if (data < (q1 - 1.5* IQR) or data > (q3 + 1.5*IQR)):\n",
        "                outliers += 1\n",
        "        print(\"Outliers in: \\n\",col,\":\",outliers, '\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxGSVtpld-5Z"
      },
      "source": [
        "from scipy import stats\n",
        "train_num_filtered = train_num[(np.abs(stats.zscore(train_num)) < 3).all(axis=1)]\n",
        "train_num_filtered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv0ZzzpbbZVo"
      },
      "source": [
        "Now, with the data filtered, we conduct the uni-variate and bi-variate analysis again to get a better idea of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cLp3umZeCEM"
      },
      "source": [
        "for i in train_num_filtered.columns:\n",
        "    if i != 'damage_grade':\n",
        "        f, axes = plt.subplots(1,3,figsize= (16,8))\n",
        "        print (train_num_filtered[i].describe(), '\\n')\n",
        "        sb.boxplot(x= i, data= train_num_filtered, orient = \"h\", ax = axes[0])\n",
        "        sb.distplot(train_num_filtered[i], kde = True, ax = axes[1])\n",
        "        sb.violinplot(train_num_filtered[i], ax = axes[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na9dljNVdrMV"
      },
      "source": [
        "The plots are now not as skewed, standard deviations are not as wide and distinctive shapes can now be seen. The variables height percentage and age percentage seem to have peaks and are somewhat symmetrical about the median, while the variable age, has a peak, followed by decreasing counts of values after that peak. There is no smooth KDE plot for the values, indicating that the values may be more distinct. There are also lesser outliers seen in the box plots, though there are still a number of them in age."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1v57mi9eF8z"
      },
      "source": [
        "for i in train_num_filtered.columns:\n",
        "    if i != 'damage_grade':\n",
        "        f,axes = plt.subplots(1,1, figsize=(16,8))\n",
        "        sb.boxplot(x = i, y = \"damage_grade\", data = train_num_filtered, orient = \"h\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAFQlnl5cPBF"
      },
      "source": [
        "While there are some distinctions in the values of these variables and the damage grades, there still appears to be no clear distinction, thus we will look at the correlation between the variables and the damage grade to get a clearer idea of what features are important in classifying if a building will receive the least damage possible during an earthquake. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_NZOw1DQJBI"
      },
      "source": [
        "corr_df = train_num.corr()\n",
        "\n",
        "# Correlation matrix for train num data\n",
        "sb.heatmap(corr_df, annot=True, linewidths=2, fmt= '.2f', cmap = \"BuGn\", vmin=-1, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA85rvSihiJC"
      },
      "source": [
        "Looking at the correlation of the variables with damage grade, there seems to be a low negative correlation of damage grade with area percentage, a low positive correlation with age and an even lower positive correlation with height percentage. This could indicate that these values are not very important to predicting the damage grade of buildings during an earthquake."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92VHc4fIhZWP"
      },
      "source": [
        "corr_df0 = train_num_filtered.corr()\n",
        "\n",
        "# Correlation matrix for train num data\n",
        "sb.heatmap(corr_df0, annot=True, linewidths=2, fmt= '.2f', cmap = \"BuGn\", vmin=-1, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUTjRDgwi1qV"
      },
      "source": [
        "Now, we will move on to the analysis of categorical variables, non-inclusive of binary variables. We took out building ID as it was a random unique identifier of values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVMNiuArLEF0"
      },
      "source": [
        "train_cat = train_data.drop(columns = ['age','area_percentage','height_percentage'])\n",
        "train_cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBBeXguULEF2"
      },
      "source": [
        "# Remove secondary use & building_id, not relevant as predictor to damage\n",
        "secondary_use = train_cat[{'has_secondary_use','has_secondary_use_agriculture','has_secondary_use_hotel','has_secondary_use','has_secondary_use_rental','has_secondary_use_institution','has_secondary_use_school','has_secondary_use_industry','has_secondary_use_health_post','has_secondary_use_gov_office','has_secondary_use_use_police','has_secondary_use_other'}]\n",
        "train_cat = train_cat.drop(columns = ['building_id','has_secondary_use','has_secondary_use_agriculture','has_secondary_use_hotel','has_secondary_use','has_secondary_use_rental','has_secondary_use_institution','has_secondary_use_school','has_secondary_use_industry','has_secondary_use_health_post','has_secondary_use_gov_office','has_secondary_use_use_police','has_secondary_use_other'])\n",
        "train_cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic8HBRD_AvLK"
      },
      "source": [
        "for i in train_cat:\n",
        "  train_cat[i]=train_cat[i].astype(\"category\")\n",
        "  print(train_cat[i].describe(), '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2RH2IT7jrUP"
      },
      "source": [
        "We converted the data type of the objects to category and when analysing the data found that count floors and count families variables had distinctive values despite being numerical variables, thus converted them into categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYDF0_LZgNzV"
      },
      "source": [
        "# Converting certain numerical data type into categorical data type\n",
        "count_floors = pd.DataFrame(train_cat['count_floors_pre_eq'])\n",
        "count_floors = count_floors.astype(\"category\")\n",
        "print(count_floors.describe(), '\\n')\n",
        "\n",
        "count_families = pd.DataFrame(train_cat['count_families'])\n",
        "count_families = count_families.astype(\"category\")\n",
        "print (count_families.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCBC4iAPAccm"
      },
      "source": [
        "train_cat.dtypes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3kUMDH6LEF4"
      },
      "source": [
        "# Remove superstructure columns(binary) and adding the newly converted categorical data types\n",
        "#train_cat_1 = train_cat.iloc[:,:10] #until plan config\n",
        "#train_cat_2 = train_cat.iloc[:,21:] # legal ownership until damage_grade\n",
        "#train_cat_final = train_cat_1.join(train_cat_2) \n",
        "#train_cat_final = train_cat_final.drop(columns = 'count_families', axis =1) #remove old numerical type\n",
        "#train_cat_final = pd.concat([train_cat_final,count_floors.reindex(index=train_cat_final.index),count_families.reindex(index=train_cat_final.index)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tETkiXprA6EL"
      },
      "source": [
        "train_cat_final = train_cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtWNzwJWkDw8"
      },
      "source": [
        "We then started our uni-variate analysis of categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_JAqLY_LEF7"
      },
      "source": [
        "# For loop for catplot of each categorical variable\n",
        "# Uni-variate analysis\n",
        "for i in train_cat_final.columns:\n",
        "    if i != 'damage_grade':\n",
        "        print (train_cat_final[i].describe(), \"\\n\")\n",
        "        #f,axes = plt.subplots(1,1, figsize=(12,8))\n",
        "        sb.catplot(y= i, data = train_cat_final, kind= \"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSXevnn_C2Zv"
      },
      "source": [
        "1.   geo_level_1_id:\n",
        "A wide distribution of classes, with a large group in category 6 to 8, 10, 17, 20 to 22, 25 to 27.\n",
        "2.   geo_level_2_id: (?) idk what happened to the catplot\n",
        "3.   geo_level_3_id: (?) idk what happened to the catplot\n",
        "4.   land_surface_condition:\n",
        "Imbalanced data, biased towards majority group t. Must do over/undersampling to get a more balanced data set.\n",
        "5. foundation_type:\n",
        "Imbalanced data, biased towards majority group r. Possible foundation type with lowest damage is i due to highest no. of buildings in damage grade 1. Must do over/undersampling to get a more balanced data set.\n",
        "6. roof_type:\n",
        "Imbalanced data, biased towards majority group n. Must do over/undersampling to get a more balanced data set.\n",
        "7. ground_floor_type:\n",
        "Imbalanced data, biased towards majority group f. Must do over/undersampling to get a more balanced data set.\n",
        "8. other_floor_type:\n",
        "Although there is a majority of q, there is still a reasonable amount of data in other floor types to consider it as an important factor to analyze.\n",
        "9. position:\n",
        "Imbalanced data, biased towards majority group s, but there are still reasonable amounts of data in other position classes to consider it as an important predictor.\n",
        "10. plan_configuration:\n",
        "The catplot shows that there is clearly an imbalance of the data set as majority of the buildings have plan configuration d. After doing a joint plot and decision tree with the damage grade, we can determine if this will be an important factor in building more earthquake resistant houses. \n",
        "11. legal_ownership_status:\n",
        "Imbalanced data, biased towards majority group v. Must do over/undersampling to get a more balanced data set.\n",
        "12. count_families:\n",
        "Imbalanced data, biased towards majority group 1. Must do over/undersampling to get a more balanced data set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLlLu8vWkUTJ"
      },
      "source": [
        "We then do our bi-variate analysis using heatmaps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaBvejmmLEF9"
      },
      "source": [
        "# For loop for heatmap against damage_grade (response variable) (categorical-categorical)\n",
        "# Bi-variate analysis\n",
        "for i in range(3,11):\n",
        "    f,axes = plt.subplots(1,1,figsize = (20,12))\n",
        "    sb.heatmap(train_cat_final.groupby([train_cat_final.iloc[:,i], 'damage_grade']).size().unstack(), \n",
        "           linewidths = 1, annot = True, annot_kws = {\"size\": 15}, cmap = \"BuGn\", fmt= '.2f')\n",
        "for i in range(12,14):\n",
        "    f,axes = plt.subplots(1,1,figsize = (20,12))\n",
        "    sb.heatmap(train_cat_final.groupby([train_cat_final.iloc[:,i], 'damage_grade']).size().unstack(), \n",
        "           linewidths = 1, annot = True, annot_kws = {\"size\": 15}, cmap = \"BuGn\", fmt= '.2f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ6dhsX9C5av"
      },
      "source": [
        "Not much can be inferred from the heatmap because the datasets are all mostly biased/ skewed towards a majority group, resulting in a larger absolute number for that specific class. Under/Oversampling would be required to get a more balanced data set for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2ZjRodvkoir"
      },
      "source": [
        "We now do analysis of the binary variables using bi-variate analysis via heatmaps to see if there are any links between them and the damage grade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccf4g5RHVh--"
      },
      "source": [
        "bincols = ['has_superstructure_adobe_mud',\n",
        "          'has_superstructure_mud_mortar_stone','has_superstructure_stone_flag',\n",
        "          'has_superstructure_cement_mortar_stone','has_superstructure_mud_mortar_brick',\n",
        "          'has_superstructure_cement_mortar_brick','has_superstructure_timber',\n",
        "          'has_superstructure_bamboo','has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered',\n",
        "          'has_superstructure_other']\n",
        "          #'has_secondary_use',\n",
        "           #'has_secondary_use_agriculture','has_secondary_use_hotel','has_secondary_use_rental',\n",
        "           #'has_secondary_use_institution','has_secondary_use_school','has_secondary_use_industry',\n",
        "           #'has_secondary_use_health_post','has_secondary_use_gov_office','has_secondary_use_use_police',\n",
        "           #'has_secondary_use_other','damage_grade']\n",
        "train_bin = train_data[bincols]+train_data['damage_grade']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8WO-98_Vwl2"
      },
      "source": [
        "# For loop for heatmap against damage_grade (response variable) (categorical-categorical)\n",
        "# Bi-variate analysis\n",
        "for i in train_bin.columns:\n",
        "    if i != 'damage_grade':\n",
        "        f,axes = plt.subplots(1,1,figsize = (20,12))\n",
        "        sb.heatmap(train_bin.groupby([train_bin[i], 'damage_grade']).size().unstack(), \n",
        "           linewidths = 1, annot = True, annot_kws = {\"size\": 15}, cmap = \"BuGn\", fmt= '.2f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-EnJZN1ls_X"
      },
      "source": [
        "//think of a way to describe heatmaps//"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne14fCjDGzV1"
      },
      "source": [
        "# Data Cleaning, Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DvzBjFmmHuP"
      },
      "source": [
        "Now, we begin to prepare and clean the data for feature selection and machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLHYt6DavLnR"
      },
      "source": [
        "# for combining with categorical data later\n",
        "train_num_filtered = train_num_filtered.drop(columns = 'damage_grade')\n",
        "train_num_filtered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwvCs3UkvOnv"
      },
      "source": [
        "for i in train_cat_final.columns:\n",
        "    print(train_cat_final[i].dropna().value_counts(), '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KXS7VehvVFZ"
      },
      "source": [
        "# To be used in for loop because we are modifying train_cat_final later\n",
        "train_cat_data = train_cat_final.copy()\n",
        "train_cat_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgOEQN74nCk0"
      },
      "source": [
        "We decided to take away minority class values, which have a count of less than 2000, in the categorical variables as we are focusing on the most feasible, optimal way to build a building least susceptible to earthquake damage, hence these classes may not be useful in finding the most feasible building against earthquakes as only a minority (<10%) can use these classes.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GP3D3V3vXh_"
      },
      "source": [
        "from collections import Counter\n",
        "for col in train_cat_data.columns: #ignoring geo_level_ids because there would be too many minorities (unique random ids)\n",
        "    if col != 'geo_level_1_id' and col != 'geo_level_2_id':\n",
        "        if col != 'geo_level_3_id':\n",
        "            Data_list = train_cat_data[col].values.tolist() #convert each column series into a list\n",
        "            Column_frequency = dict(Counter(Data_list)) # Use counter to count freq of each unique value, convert into dict\n",
        "            minority = [] #create a list for all minority classes per column\n",
        "            for unique,count in Column_frequency.items():\n",
        "                if count< 2000:\n",
        "                    minority.append(unique)\n",
        "            print (col, minority) # These are the minority classes we are removing\n",
        "            for item in minority:\n",
        "                train_cat_final = pd.DataFrame(train_cat_final.where((train_cat_final[col]!= item)).dropna())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V25uwEVSvblv"
      },
      "source": [
        "# After removal of minority classes\n",
        "for i in train_cat_final.columns:\n",
        "    print(train_cat_final[i].value_counts(), '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qe9bnjGHD6J"
      },
      "source": [
        "train_cat_final.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4YNbaFbpJxG"
      },
      "source": [
        "We will now do one-hot encoding to facilitate machine learning modelling in the later stage of this project "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV2uCsmwJ7N3"
      },
      "source": [
        "# onehot encoding for cat variables\n",
        "train_cat_onehot = train_cat_final.drop(columns=[\"geo_level_1_id\",\"geo_level_2_id\",\"geo_level_3_id\", \"damage_grade\"])\n",
        "train_cat_onehot = pd.get_dummies(train_cat_onehot.drop(columns=bincols))\n",
        "train_cat_onehot = pd.get_dummies(train_cat_onehot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgTH95cBKktu"
      },
      "source": [
        "# removing onehot columns with all the same value as it will not be able to affect results in ML modelling\n",
        "train_cat_onehot = train_cat_onehot.loc[:, (train_cat_onehot != train_cat_onehot.iloc[0]).any()] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiUJya3xLH35"
      },
      "source": [
        "for i in train_cat_onehot:\n",
        "  train_cat_onehot[i]=train_cat_onehot[i].astype(\"category\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utnpXiXlEqAm"
      },
      "source": [
        "train_cat_onehot = pd.concat([train_cat_onehot, train_cat_final[[\"geo_level_1_id\", \"geo_level_2_id\",\"geo_level_3_id\"]]], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS7fR7GypxoO"
      },
      "source": [
        "Now we move on to combining numerical and categorical data and filling up null values using interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_ajjmfgvfdx"
      },
      "source": [
        "# Combining both numerical and categorical data\n",
        "combined_df = pd.concat([train_cat_onehot,train_num_filtered], axis=1)\n",
        "combined_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaffLDn_vmCH"
      },
      "source": [
        "# Checking for any Null values.\n",
        "combined_df.loc[pd.isnull(combined_df).any(1),:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB_shuhcqgzy"
      },
      "source": [
        "We also visualise null values using the library missingno in matrix format to find the pattern of missingness and bar chart format to find out how many missing values there are in each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HwbALMZKYEo"
      },
      "source": [
        "#visualising null values\n",
        "msn.matrix(combined_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgnb8Xg_MEV0"
      },
      "source": [
        "#visualising null data in a bar chart\n",
        "msn.bar(combined_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjlu1ueLvoAP"
      },
      "source": [
        "# Seems there are NULL values in numerical data, use interpolation\n",
        "for col in train_num_filtered.columns: \n",
        "    combined_df[col] = combined_df[col].interpolate('linear')\n",
        "# Check for NULL again\n",
        "#msn.matrix(combined_df.sample(260600))\n",
        "result = combined_df.isnull().values.any()\n",
        "print(\"Any null values: \", result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEm9Jhw-NvN6"
      },
      "source": [
        "combined_df = pd.concat([combined_df, train_data[['damage_grade']]], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uogkGW-NJEt"
      },
      "source": [
        "combined_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm_rhN3xrnX0"
      },
      "source": [
        "Now we will move on to dealing with minority classes with respect to other classes using smote to oversample minority classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWZwDbXZMXy9"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Resample the minority class. You can change the strategy to 'auto' if you are not sure.\n",
        "sm = SMOTE()\n",
        "\n",
        "# Fit the model to generate the data.\n",
        "oversampled_trainX, oversampled_trainY = sm.fit_sample(combined_df.drop(columns='damage_grade', axis=1), train_data['damage_grade'])\n",
        "oversampled_train = pd.concat([pd.DataFrame(oversampled_trainX), pd.DataFrame(oversampled_trainY)], axis=1)\n",
        "oversampled_train.columns = combined_df.columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2rvJR-mOMFV"
      },
      "source": [
        "oversampled_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vpk-58nPkb3"
      },
      "source": [
        "# convert float to cat values for binary data after smote resampling, idk if we can actually do this eh\n",
        "# but on jupyter nb, it doesnt return float values after smote but it does here on colab \n",
        "for i in oversampled_train:\n",
        "  if i not in train_num_filtered.columns:\n",
        "    oversampled_train[i]=oversampled_train[i].astype(\"category\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNURS8ykQFsM"
      },
      "source": [
        "oversampled_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KtARrvbTMQK"
      },
      "source": [
        "# to show the better balance in classes after smote using catplot\n",
        "for i in train_cat_onehot.columns:\n",
        "    if i != \"damage_grade\":\n",
        "      if i not in [\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"]:\n",
        "        sb.catplot(y = i, hue=\"damage_grade\", data = oversampled_train, kind = \"count\", height = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWGUPnnqVSAV"
      },
      "source": [
        " # to show the better balance in classes after smote using heatmap\n",
        "for i in train_cat_onehot.columns:\n",
        "    if i != \"damage_grade\":\n",
        "      if i not in [\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\"]:       \n",
        "        f,axes = plt.subplots(1,1,figsize = (10,8))\n",
        "        sb.heatmap(oversampled_train.groupby([oversampled_train[i], 'damage_grade']).size().unstack(), \n",
        "           linewidths = 1, annot = True, annot_kws = {\"size\": 15}, cmap = \"BuGn\", fmt= '.2f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDsCseavFeT6"
      },
      "source": [
        "We then normalize the data using min-max scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AANymtpsQLMM"
      },
      "source": [
        "#minmax scaling of numerical variables\n",
        "mm_scaler = preprocessing.MinMaxScaler()\n",
        "train_num_mm = mm_scaler.fit_transform(oversampled_train[[\"age\", \"area_percentage\", \"height_percentage\"]])\n",
        "oversampled_train[[\"age\", \"area_percentage\", \"height_percentage\"]] = pd.DataFrame(train_num_mm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qbDGEYVR0z3"
      },
      "source": [
        "oversampled_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIogcm2BKCNl"
      },
      "source": [
        "for i in oversampled_train:\n",
        "  if i not in train_num_filtered.columns:\n",
        "    oversampled_train[i]=oversampled_train[i].astype(\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdJLNAo2Sb-z"
      },
      "source": [
        "train_df_final = oversampled_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFyqs5ZyXJ9Z"
      },
      "source": [
        "corr_train_final = train_df_final.corr() # Balanced by SMOTE DataFrame Correlation\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize=(20,10))         \n",
        "sb.heatmap(corr_train_final, cmap='YlGnBu', annot_kws={'size':30})\n",
        "ax.set_title(\"Final Train Data Correlation Matrix\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK3X1O_MWzjL"
      },
      "source": [
        "X = train_df_final.drop(columns= \"damage_grade\")\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgGFnpOqW7sI"
      },
      "source": [
        "y = train_df_final[[\"damage_grade\"]]\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm3PAuL_FlO8"
      },
      "source": [
        "We//talk about kfold \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
        "https://stackoverflow.com/questions/45969390/difference-between-stratifiedkfold-and-stratifiedshufflesplit-in-sklearn // "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg99yfoUWr34"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold()\n",
        "skf.get_n_splits(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S74Cu8QnX2eY"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.loc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7V0yQK2LEGJ"
      },
      "source": [
        "feature_name = list(X.columns)\n",
        "# no of maximum features we need to select, ~15% of features\n",
        "num_feats=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zmKP3rNLEGH"
      },
      "source": [
        "len(X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm6-LOmMHNCJ"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-KZxR02del0"
      },
      "source": [
        "Chi2 Test (delete later maybe, generic)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p-SOfgkLEGL"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "X_norm = MinMaxScaler().fit_transform(X)\n",
        "chi_selector = SelectKBest(chi2, k=num_feats)\n",
        "chi_selector.fit(X_norm, y)\n",
        "chi_support = chi_selector.get_support()\n",
        "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
        "print(str(len(chi_feature)), 'selected features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi3VNphAdhjn"
      },
      "source": [
        "Pearson's Correlation Test (delete later maybe, generic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhwWrz1ELEGN"
      },
      "source": [
        "def cor_selector(X, y,num_feats):\n",
        "    cor_list = []\n",
        "    feature_name = X.columns.tolist()\n",
        "    # calculate the correlation with y for each feature\n",
        "    for i in X.columns.tolist():\n",
        "        cor = np.corrcoef(X[i], y)[0, 1]\n",
        "        cor_list.append(cor)\n",
        "    # replace NaN with 0\n",
        "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "    # feature name\n",
        "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
        "    # feature selection? 0 for not select, 1 for select\n",
        "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
        "    return cor_support, cor_feature\n",
        "cor_support, cor_feature = cor_selector(X, y,num_feats)\n",
        "print(str(len(cor_feature)), 'selected features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA_7f2OCdmrt"
      },
      "source": [
        "RFE Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slu9KHR1LEGP"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_feats, step=10, verbose=5)\n",
        "rfe_selector.fit(X_norm, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaDSa04vLEGR"
      },
      "source": [
        "rfe_support = rfe_selector.get_support()\n",
        "rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
        "print(str(len(rfe_feature)), 'selected features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aal90Oddd0Wf"
      },
      "source": [
        "Logistic Regression Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORaTMsuYLEGU"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear'), max_features=num_feats)\n",
        "embeded_lr_selector.fit(X_norm, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOmiBeJlLEGX"
      },
      "source": [
        "embeded_lr_support = embeded_lr_selector.get_support()\n",
        "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
        "print(str(len(embeded_lr_feature)), 'selected features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cue8YT0bd5uu"
      },
      "source": [
        "Random Forest Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT0U_t8fLEGZ"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100))\n",
        "embeded_rf_selector.fit(X, y.values.ravel())\n",
        "\n",
        "embeded_rf_support = embeded_rf_selector.get_support()\n",
        "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
        "print(str(len(embeded_rf_feature)), 'selected features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71ZbAnmwd_z_"
      },
      "source": [
        "LightGBM Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mk75XGDLEGd"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
        "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
        "\n",
        "embeded_lgb_selector = SelectFromModel(lgbc)\n",
        "embeded_lgb_selector.fit(X, y)\n",
        "\n",
        "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
        "embeded_lgb_feature = X.loc[:,embeded_lgb_support].columns.tolist()\n",
        "print(str(len(embeded_lgb_feature)), 'selected features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc3RxW1-LEGg"
      },
      "source": [
        "# put all selection together\n",
        "feature_selection_df = pd.DataFrame({'Feature':feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistics':embeded_lr_support,'Random Forest':embeded_rf_support, 'LightGBM':embeded_lgb_support, })\n",
        "# count the selected times for each feature\n",
        "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
        "# display the top 100\n",
        "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
        "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
        "feature_selection_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTpl3__VLEGh"
      },
      "source": [
        "selected_features_df = feature_selection_df[(feature_selection_df['Total']>=2)]\n",
        "selected_features_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KshFzN8kLEGj"
      },
      "source": [
        "selected_features = list(selected_features_df.Feature)\n",
        "selected_features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWwhO0ZRLEGl"
      },
      "source": [
        "y = pd.DataFrame(traindf['damage_grade'])\n",
        "y = pd.get_dummies(y)\n",
        "\n",
        "X = pd.DataFrame(traindf)\n",
        "X = X.drop(columns=\"damage_grade\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNqcE0saLEGn"
      },
      "source": [
        "X = pd.DataFrame(X[selected_features])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mad88MKXSBzH"
      },
      "source": [
        "corr_final_df = X.join(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rNXd7gbSSqa"
      },
      "source": [
        "#heat map for final data set\n",
        "f, ax = plt.subplots(figsize=(20, 24))\n",
        "sb.heatmap(corr_final_df.corr(), annot=True, linewidths=.5, ax = ax, cmap = \"BuGn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6fDz7xsHWoB"
      },
      "source": [
        "# Machine Learning model/ Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BExddzhTLEGo"
      },
      "source": [
        "# can delete \n",
        "#oversampling using smote for imbalanced classes\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "X_smote, y_smote = smote.fit_sample(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3UytLbZp07E"
      },
      "source": [
        "y_smote"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njOmArLvLEGr"
      },
      "source": [
        "#can delete\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Split the Dataset into Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size = 0.25)\n",
        "\n",
        "#min max scaling\n",
        "from sklearn import preprocessing\n",
        "mm_scaler = preprocessing.MinMaxScaler()\n",
        "X_train = mm_scaler.fit_transform(X_train)\n",
        "X_test = mm_scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pQZvb8gLEG-"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "# Decision Tree using Train Data\n",
        "dectree = DecisionTreeClassifier(max_depth = 12)  # create the decision tree object\n",
        "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
        "\n",
        "# Predict Response corresponding to Predictors\n",
        "y_train_pred = dectree.predict(X_train)\n",
        "y_test_pred = dectree.predict(X_test)\n",
        "\n",
        "# Export the Decision Tree as a dot object\n",
        "treedot = export_graphviz(dectree,                                      # the model\n",
        "                          feature_names = selected_features,          # the features \n",
        "                          out_file = None,                              # output file\n",
        "                          filled = True,                                # node colors\n",
        "                          rounded = True,                               # make pretty\n",
        "                          special_characters = True)                    # postscript\n",
        "\n",
        "# Render using graphviz\n",
        "graphviz.Source(treedot)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht-ETnoZFZK6"
      },
      "source": [
        "# Check the Goodness of Fit (on Train Data)\n",
        "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
        "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
        "print()\n",
        "\n",
        "# Check the Goodness of Fit (on Test Data)\n",
        "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
        "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
        "print()\n",
        "\n",
        "# Plot the Confusion Matrix for Train and Test\n",
        "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
        "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0], cmap = \"BuGn\")\n",
        "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
        "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1], cmap = \"BuGn\")\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(y_test, y_test_pred, average='micro')\n",
        "print(\"f1_score is\", f1_score)\n",
        "print(\"\\n\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = y_test\n",
        "y_pred = y_test_pred\n",
        "target_names = ['damage_grade_1', 'damage_grade_2', 'damage_grade_3']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tY8xK1HLEHu"
      },
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "nb.fit(X_train,y_train)\n",
        "\n",
        "#Predict Output\n",
        "y_train_pred = nb.predict(X_train)\n",
        "y_test_pred = nb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8GPPsuHep1f"
      },
      "source": [
        "# Check the Goodness of Fit (on Train Data)\n",
        "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
        "print(\"Classification Accuracy \\t:\", nb.score(X_train, y_train))\n",
        "print()\n",
        "\n",
        "# Check the Goodness of Fit (on Test Data)\n",
        "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
        "print(\"Classification Accuracy \\t:\", nb.score(X_test, y_test))\n",
        "print()\n",
        "\n",
        "# Plot the Confusion Matrix for Train and Test\n",
        "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
        "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0], cmap = \"BuGn\")\n",
        "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
        "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1], cmap = \"BuGn\")\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(y_test, y_test_pred, average='micro')\n",
        "print(\"f1_score is\", f1_score)\n",
        "print(\"\\n\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = y_test\n",
        "y_pred = y_test_pred\n",
        "target_names = ['damage_grade_1', 'damage_grade_2', 'damage_grade_3']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwExU9qTVlOS"
      },
      "source": [
        "#this takes like 5000 years to load lol but the f1 score is high \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_test_pred = knn.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvSwFlVGKVIj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import datasets, neighbors\n",
        "from mlxtend.plotting import plot_decision_regions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RldKFSn_euj-"
      },
      "source": [
        "# Check the Goodness of Fit (on Train Data)\n",
        "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
        "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
        "print()\n",
        "\n",
        "# Check the Goodness of Fit (on Test Data)\n",
        "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
        "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
        "print()\n",
        "\n",
        "# Plot the Confusion Matrix for Train and Test\n",
        "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
        "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0], cmap = \"BuGn\")\n",
        "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
        "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1], cmap = \"BuGn\")\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(y_test, y_test_pred, average='micro')\n",
        "print(\"f1_score is\", f1_score)\n",
        "print(\"\\n\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = y_test\n",
        "y_pred = y_test_pred\n",
        "target_names = ['damage_grade_1', 'damage_grade_2', 'damage_grade_3']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3FVlCzBtW_R"
      },
      "source": [
        "## CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq_inZKMtZTk"
      },
      "source": [
        "#!pip3 install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "import catboost\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYxXnuIMtiUp"
      },
      "source": [
        "cat_features = list(range(0, X.shape[1]))\n",
        "print(cat_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n74ptydJtrWl"
      },
      "source": [
        "X_traincat, X_val, y_traincat, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXEoEm73trKt"
      },
      "source": [
        "clf = CatBoostClassifier(\n",
        "    iterations=5, \n",
        "    learning_rate=0.1, \n",
        "    #loss_function='CrossEntropy'\n",
        ")\n",
        "\n",
        "\n",
        "clf.fit(X_traincat, y_traincat, \n",
        "        cat_features=cat_features, \n",
        "        eval_set=(X_val, y_val), \n",
        "        verbose=False\n",
        ")\n",
        "\n",
        "print('CatBoost model is fitted: ' + str(clf.is_fitted()))\n",
        "print('CatBoost model parameters:')\n",
        "print(clf.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMlIQxBMtrAe"
      },
      "source": [
        "clf = CatBoostClassifier(\n",
        "    iterations=10,\n",
        "#     verbose=5,\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_traincat, y_traincat,\n",
        "    cat_features=cat_features,\n",
        "    eval_set=(X_val, y_val),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrp5H5ydMGuu"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkELXc4Rtq0k"
      },
      "source": [
        "X = train_df_final.drop(columns=\"damage_grade\")\n",
        "y = train_df_final[\"damage_grade\"]\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear'))\n",
        "embeded_lr_selector.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7jyyQw3tqqg"
      },
      "source": [
        "logreg = LogisticRegression(C=1e5)\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SSsSz9qtqUu"
      },
      "source": [
        "#Predict Output\n",
        "y_train_pred = logreg.predict(X_train)\n",
        "y_test_pred = logreg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P84Xiz67Bm4Y"
      },
      "source": [
        "# Check the Goodness of Fit (on Train Data)\n",
        "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
        "print(\"Classification Accuracy \\t:\", logreg.score(X_train, y_train))\n",
        "print()\n",
        "\n",
        "# Check the Goodness of Fit (on Test Data)\n",
        "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
        "print(\"Classification Accuracy \\t:\", logreg.score(X_test, y_test))\n",
        "print()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Plot the Confusion Matrix for Train and Test\n",
        "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
        "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0], cmap = \"BuGn\")\n",
        "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
        "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1], cmap = \"BuGn\")\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(y_test, y_test_pred, average='micro')\n",
        "print(\"f1_score is\", f1_score)\n",
        "print(\"\\n\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_true = y_test\n",
        "y_pred = y_test_pred\n",
        "target_names = ['damage_grade_1', 'damage_grade_2', 'damage_grade_3']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8p-I2geNDfh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}